---  
title: Go 101 | The go workshop
date: '2022-10-07'  
tags: [go, golang, concurrency, workshop]  
description: Prerequisite and dependencies for the 11ty Workshop  
permalink: posts/{{ title | slug }}/index.html
author_name: The mentor team of HACKERSPACE PESUECC
author_link : /members
---

> Note : Setup and Pre-requisites are a must, the mentors will NOT be helping you install go during workshop.

## Pre-requisites | Setup 

For linux :
```bash
sudo rm -rf /usr/local/go && tar -C /usr/local -xzf go1.19.1.linux-amd64.tar.gz
export PATH=$PATH:/usr/local/go/bin
go version
```
If after the 3 commands above, if you get the 1.19.1 version as output, you are good to go!

If you are on Windows, download the [Go Installer](https://go.dev/dl/go1.19.1.windows-amd64.msi) and run it. 

If you are on MacOS, download the [Go Installer](https://go.dev/dl/go1.19.1.darwin-amd64.pkg) and run it.

## What is go? [Speaker-1]

## Why go and how it's similar to C? [Speaker-1]

## 01-The basic syntax  [Speaker-1]

## 02-An example, rather slow one vs what we are about to do [Speaker-1]

// Single threaded fizz buzz code along with time command

## 03-More about syntax [Speaker-2]

## 04-Concurrency

### What are threads, a very naive explaination [Speaker-2]

// Explain it to a 5 year old
Before we get started with concurrency, lets quickly skim through some basics. Try to answer the below own questions.
1. What is a program?
2. What is a process?

So, in layman terms    
* **Program** is a written set of instructions or syntax with some functionality which will be executed by the computer.
* **Process** is a program in execution.
* As seen in a computer, multiple processes can execute simultaneously and well that's multiprocessing.
* But the overhead and the work put on creating a process in any OS is quite heavy.
* We use **Threads** and the concept of **Multithreading** to achieve what processes and multiprocessing does but with lower overhead and much much more simplicity.
* So, What exactly is a thread?
* A **Thread** is an independent sequence of execution within a process.
* Lets take an example,
* Patty and Joe 
### Go routines [Speaker-2]

//This has to end with the question, how will these routines work together?
// Answer is channels

### Go channels [Speaker-3]

- Theory of channels, Why channels : 

Let's consider a like counter...a counter in which a person can either like(+1) or dislike (-1). But before I can explain race conditions. We need to understand the von neumann cycle.

Von Neumann architechture ans this is it : 
```
fetch->decode->execute->write

What's to note is the "fetch" of data that happens here before execution [that too, 2 steps before exec].
```
Let's consider that one thread each handles the incoming likes and dislikes. And as we only know normal variables in Go for now, we have no other choice but to have all these threads update the value in this "integer" variables called `likes`. Let's now consider 2 requests coming in, both likes at the EXACT SAME TIME. So two threads spawn at the same time and "fetch" the memory of variable `likes`. Both do a +1 to `likes` variable. and now store it back to the same memory. 



WAIIIIIIIITTTT, what just happened??? we got 2 like requests but our value only went up by 1??
```go
// UNSAFE AND WRONG CODE :
func rapid_likes_sender2(likes *int, wg *sync.WaitGroup){
  defer wg.Done()
  i := 0
  for i<100{
    *likes+=1
    i++
  }
}

func unsafe_likes_counter(){
  wg := new(sync.WaitGroup)
  likes := 0;
  wg.Add(100)
  i:=1
  for i<=10{
    go rapid_likes_sender2(&likes, wg)
    go rapid_likes_sender2(&likes, wg)
    go rapid_likes_sender2(&likes, wg)
    go rapid_likes_sender2(&likes, wg)
    go rapid_likes_sender2(&likes, wg)
    go rapid_likes_sender2(&likes, wg)
    go rapid_likes_sender2(&likes, wg)
    go rapid_likes_sender2(&likes, wg)
    go rapid_likes_sender2(&likes, wg)
    go rapid_likes_sender2(&likes, wg)
    i++
  }
  wg.Wait()
  print(likes)
}
```
This above is a go code to put this problem into perpective, even tho we are generating 10000 requests. We barely get the correct answer. This is a very solid introduction to race conditions and we'll discuss in short how we can avoid this. In some cases (in fortunate cases) we will only get inconsistent values, In most unfortunate situations this leads to a runtime error. With this I hope you are sold on channels, now let's look into using them.

* The basic syntax : 
```go
  first_channel := make(chan string)
  first_channel <- "Hello, World!"
  our_message := <- first_channel 
  //We have to use := for "our_message" as the variables needs to figure what it stored by itself, we can also declare its type manually
  fmt.Println(our_message)
```
So in the above code block, we see a channel that is happy to store strings, this is the same for any data type channels. But if you really did run the above code, you'll see we will get a runtime error :(. This is because we told our channel should store strings but did not mention how many, that is we have an unbuffered memory [We'll look into these shortly] . Let's fix that and look into `len` and `cap` functions of channels.

- Fixing channels : 
```go
  first_channel := make(chan string,1)
  fmt.Println("Before queuing, len :",len(first_channel)) //Shows number of queued messages in the buffer
  fmt.Println("Before queuing, cap :",cap(first_channel)) //Shows the total capacity of buffer
  first_channel <- "Hello, World!"
  fmt.Println("After queuing one string, len :",len(first_channel))
  fmt.Println("After queuing one string, cap :",cap(first_channel))
  // first_channel <- "Second message :(" //Will cause runtime, is explained in blog.
  our_message := <- first_channel 
  fmt.Println(our_message)
```
So in the above code, we see a lot going on. Let's break it down : 
  * We now have a channel size of 1, implying we can store one string in channel.
  * the `len()` prints the number of "items" buffered. 
  * the `cap()` prints the max numbers of "items" that can be buffered.
Do note, when ever the len() goes above cap() our code panic's in runtime.

- Using channels without buffering and tieing channels in with go routines:
```go
func recv_likes_and_sum(second_channel chan int, wg *sync.WaitGroup){ 
  likes := 0
  for{
    incoming_like, ok := <- second_channel 
    if !ok{
      print(likes)
      wg.Done()
      return
    }
    likes+=incoming_like
  }
}

func rapid_like_sender(channel chan int, wg *sync.WaitGroup){
  i:=0
  for i<100{
    channel<-1
    i++
  }
  wg.Done() //Does -1 to wg

}

func routines_unbuf_channel(){
  second_channel := make(chan int) //Unbuffered
  wg := new(sync.WaitGroup)
  wg2 := new(sync.WaitGroup)
  wg.Add(1)
  go recv_likes_and_sum(second_channel,wg)
  wg2.Add(100)
  //We are basically sendinf 2 requests simulatneoulsy...the case that studied before.
  i:=1
  for i<=10{
    go rapid_like_sender(second_channel, wg2)
    go rapid_like_sender(second_channel, wg2)
    go rapid_like_sender(second_channel, wg2)
    go rapid_like_sender(second_channel, wg2)
    go rapid_like_sender(second_channel, wg2)
    go rapid_like_sender(second_channel, wg2)
    go rapid_like_sender(second_channel, wg2)
    go rapid_like_sender(second_channel, wg2)
    go rapid_like_sender(second_channel, wg2)
    go rapid_like_sender(second_channel, wg2)
    i++
  }
  wg2.Wait()
  close(second_channel)
  wg.Wait()
}
```
If you are sure if a channels always has an active recviever, we can let our channels be unbuffered! And the above example is accurate 100% of the time!! With that we come to an end of looking at channels and threads communication at quite the depth!


### The same example...just over engineered! [Speaker-3]

// Has to write code along

## 05-A very simple api - NetWork Module  [Speaker-3]

## 06-What go can build! [N-Speakers]

## Refrences and Sources



